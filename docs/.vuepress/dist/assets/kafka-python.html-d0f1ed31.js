import{_ as e,p as o,q as a,a1 as t}from"./framework-5866ffd3.js";const r={},s=t('<p>Python操作Kafka的通俗总结（kafka-python） Algernon Algernon ​关注他 73 人赞同了该文章 kafka-python文档：KafkaConsumer - kafka-python 2.0.2-dev documentation</p><p>一、基本概念 Topic：一组消息数据的标记符； Producer：生产者，用于生产数据，可将生产后的消息送入指定的Topic； Consumer：消费者，获取数据，可消费指定的Topic； Group：消费者组，同一个group可以有多个消费者，一条消息在一个group中，只会被一个消费者获取； Partition：分区，为了保证kafka的吞吐量，一个Topic可以设置多个分区。同一分区只能被一个消费者订阅。 二、本地安装与启动（基于Docker） 下载zookeeper镜像与kafka镜像： docker pull wurstmeister/zookeeper docker pull wurstmeister/kafka 2. 本地启动zookeeper</p><p>docker run -d --name zookeeper -p 2181:2181 -t wurstmeister/zookeeper 3. 本地启动kafka</p><p>docker run -d --name kafka --publish 9092:9092 --link zookeeper <br> --env KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 <br> --env KAFKA_ADVERTISED_HOST_NAME=localhost <br> --env KAFKA_ADVERTISED_PORT=9092 <br> wurstmeister/kafka:latest 注意：上述代码，将kafka启动在9092端口</p><ol start="4"><li>进入kafka bash</li></ol><p>docker exec -it kafka bash cd /opt/kafka/bin 5. 创建Topic，分区为2，Topic name为&#39;kafka_demo&#39;</p><p>kafka-topics.sh --create --zookeeper zookeeper:2181 <br> --replication-factor 1 --partitions 2 --topic kafka_demo 6. 查看当前所有topic</p><p>kafka-topics.sh --zookeeper zookeeper:2181 --list 7. 安装kafka-python</p><p>pip install kafka-python 三、生产者（Producer）与消费者（Consumer） 生产者和消费者的简易Demo，这里一起演示：</p><p>from kafka import KafkaProducer, KafkaConsumer from kafka.errors import kafka_errors import traceback import json</p><p>def producer_demo():</p><h1 id="假设生产的消息为键值对-不是一定要键值对-且序列化方式为json" tabindex="-1"><a class="header-anchor" href="#假设生产的消息为键值对-不是一定要键值对-且序列化方式为json" aria-hidden="true">#</a> 假设生产的消息为键值对（不是一定要键值对），且序列化方式为json</h1><p>producer = KafkaProducer( bootstrap_servers=[&#39;localhost:9092&#39;], key_serializer=lambda k: json.dumps(k).encode(), value_serializer=lambda v: json.dumps(v).encode())</p><h1 id="发送三条消息" tabindex="-1"><a class="header-anchor" href="#发送三条消息" aria-hidden="true">#</a> 发送三条消息</h1><p>for i in range(0, 3): future = producer.send( &#39;kafka_demo&#39;, key=&#39;count_num&#39;, # 同一个key值，会被送至同一个分区 value=str(i), partition=1) # 向分区1发送消息 print(&quot;send {}&quot;.format(str(i))) try: future.get(timeout=10) # 监控是否发送成功<br> except kafka_errors: # 发送失败抛出kafka_errors traceback.format_exc()</p><p>def consumer_demo(): consumer = KafkaConsumer( &#39;kafka_demo&#39;, bootstrap_servers=&#39;:9092&#39;, group_id=&#39;test&#39; ) for message in consumer: print(&quot;receive, key: {}, value: {}&quot;.format( json.loads(message.key.decode()), json.loads(message.value.decode()) ) ) 这里建议起两个terminal，或者两个jupyter notebook页面来验证。</p><p>先执行消费者：</p><p>consumer_demo() 再执行生产者：</p><p>producer_demo() 会看到如下输出：</p><blockquote><blockquote><blockquote><p>producer_demo() send 0 send 1 send 2</p></blockquote></blockquote></blockquote><blockquote><blockquote><blockquote><p>consumer_demo() receive, key: count_num, value: 0 receive, key: count_num, value: 1 receive, key: count_num, value: 2 四、消费者进阶操作 （1）初始化参数：</p></blockquote></blockquote></blockquote><p>列举一些KafkaConsumer初始化时的重要参数：</p><p>group_id 高并发量，则需要有多个消费者协作，消费进度，则由group_id统一。例如消费者A与消费者B，在初始化时使用同一个group_id。在进行消费时，一条消息被消费者A消费后，在kafka中会被标记，这条消息不会再被B消费（前提是A消费后正确commit）。</p><p>key_deserializer， value_deserializer 与生产者中的参数一致，自动解析。</p><p>auto_offset_reset 消费者启动的时刻，消息队列中或许已经有堆积的未消费消息，有时候需求是从上一次未消费的位置开始读（则该参数设置为earliest），有时候的需求为从当前时刻开始读之后产生的，之前产生的数据不再消费（则该参数设置为latest）。</p><p>enable_auto_commit， auto_commit_interval_ms 是否自动commit，当前消费者消费完该数据后，需要commit，才可以将消费完的信息传回消息队列的控制中心。enable_auto_commit设置为True后，消费者将自动commit，并且两次commit的时间间隔为auto_commit_interval_ms。</p><p>（2）手动commit</p><p>def consumer_demo(): consumer = KafkaConsumer( &#39;kafka_demo&#39;, bootstrap_servers=&#39;:9092&#39;, group_id=&#39;test&#39;, enable_auto_commit=False ) for message in consumer: print(&quot;receive, key: {}, value: {}&quot;.format( json.loads(message.key.decode()), json.loads(message.value.decode()) ) ) consumer.commit()</p><p>（3）查看kafka堆积剩余量</p><p>在线环境中，需要保证消费者的消费速度大于生产者的生产速度，所以需要检测kafka中的剩余堆积量是在增加还是减小。可以用如下代码，观测队列消息剩余量：</p><p>consumer = KafkaConsumer(topic, **kwargs) partitions = [TopicPartition(topic, p) for p in consumer.partitions_for_topic(topic)]</p><p>print(&quot;start to cal offset:&quot;)</p><h1 id="total" tabindex="-1"><a class="header-anchor" href="#total" aria-hidden="true">#</a> total</h1><p>toff = consumer.end_offsets(partitions) toff = [(key.partition, toff[key]) for key in toff.keys()] toff.sort() print(&quot;total offset: {}&quot;.format(str(toff)))</p><h1 id="current" tabindex="-1"><a class="header-anchor" href="#current" aria-hidden="true">#</a> current</h1><p>coff = [(x.partition, consumer.committed(x)) for x in partitions] coff.sort() print(&quot;current offset: {}&quot;.format(str(coff)))</p><h1 id="cal-sum-and-left" tabindex="-1"><a class="header-anchor" href="#cal-sum-and-left" aria-hidden="true">#</a> cal sum and left</h1><p>toff_sum = sum([x[1] for x in toff]) cur_sum = sum([x[1] for x in coff if x[1] is not None]) left_sum = toff_sum - cur_sum print(&quot;kafka left: {}&quot;.format(left_sum))</p>',38),p=[s];function n(i,c){return o(),a("div",null,p)}const k=e(r,[["render",n],["__file","kafka-python.html.vue"]]);export{k as default};
